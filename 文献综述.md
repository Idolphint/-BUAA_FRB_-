# 文献综述-李甜甜

文章编号：06189692

## Dynamic Segmentation  of Vocal Extract for Assamese Speech to Text Conversion using RNN

基于RNN的阿萨姆语言语音提取到文本转换的动态分割

### 背景：

语言文本转换系统STCS是一个比较成熟的系统，但这套系统转换的准确率与**音素分割**（也就是将每个音标分割出来）的准确率密切相关。在传统的分割工作里，都是采用基于先验知识的分割法，固定了分割窗口的长度。

而阿萨姆语言是一个比较特别的语言，属于印度语，但它的发音方式和其他语言也有较多不同。因此先验知识不奏效。因而引入了动态分割的办法（不是深度算法）

### 相关工作（技术关键词）：

文中主要提到的相关工作是STCS中的几种技术：

未被用到的技术：

- 常规的基于窗口（固定长度--未必是对于每个音都固定但是长度可选择的有限，且不能迭代）的转换

  基本流程为：语音-》固定窗口分割-》语音识别器-》文本

- ANN：人工神经网络，所有神经网络都包括在内。

使用到的技术：

- MA filter也就是滑动平均滤波器，用来滤掉噪音，取滑动滤波长度为10

- 阈值法，取到语音正确的开始和结尾，没什么技术含量

- LPC线性预测编码，主要思想：一个特定语音样本在当前时间可以近似为过去语音样本的线性组合。可以通过最小均方误差在实际语音样本和线性预测值之间，找到对应唯一的的参数或者预测系数。也就是说，语言只有几个特定的音素，句子就是这些音素的线性组合。

- LP分析的顺序很重要，决定了LPC特征集合的长度，在长度为35时，ANN表现很好。RNN也是表现最好

- MLP多层感知机：其实就是只有前向传播的神经网络，一般情况下表现不够好，而且容易过拟合。文章通过RNN与MLP对比，说明了MLP只能识别出元音，不能识别出辅音，所以使用RNN

- RNN循环神经网络。是加上了后反馈的MLP，因此理论上可以记住所有历史信息。而隐层数量的指定也是本文一项特色，执行隐层数量为35时最好，因为35是LPC提取出的特征数量。这里是为什么呢？？

  ![image-20200105041049481](C:\Users\litia\AppData\Roaming\Typora\typora-user-images\image-20200105041049481.png)

### 主要内容：

文章提出基于RNN的语音文本转换和动态分割音素技术，主要改进在，

- 使用了动态确定分割长度的分割办法。
- 调整LP线性预测器的预测顺序，找到表现比较好的35种特征。
- 将分割得到的语音端扔到RNN里进行语音文本转换。准确率高达94%
- RNN使用了35个隐藏层，使用了BPM后反馈方法。它还比较了LM后向传播算法，（Levenberg-Marquardth back   propagation  algorithms. ）BPM更慢但是不消耗更多内存。

下图是动态分割办法的示意图。也就是说，每次固定长度设置的小一点，如果识别不成功，将当前语音加入到上一个语音中再次识别。如果识别器识别成功，那么将语音段送给判别器判断。

![image-20200105040849290](C:\Users\litia\AppData\Roaming\Typora\typora-user-images\image-20200105040849290.png)



总体而言，使用了传统办法的动态分割，使用RNN来作为识别器，准确率高达94%。

### 其他说明：

语音的特征就是波峰和波谷的频率，因此分割音素就显得尤为重要。

### 可以借鉴的点：

我认为没有，如果有的话，那就是RNN挺好用的。



---



# A COMBINED LSTM-RNN-HMM-APPROACH FOR MEETING EVENT SEGMENTATION AND RECOGNITION

一个结合了LSTM-RNN和HMM的会议分割和识别方法    文章编号：01660362

### 背景：

为了高效的浏览和查询会议档案，诞生了自动分割和分类会议记录的技术。但是目前所有这些技术的鲁棒性都太差劲。

~~大多数研究会议记录的人都聚焦于可信的会议记录和浏览系统。~~

~~有些人主要产生演讲稿，有些工作做人的多模态跟踪与识别。有些是为了构建演示系统（不重要）。~~

一般情况下会把这些特征顺序地呈现，然后再使用标准的模式识别。但本文提出了全新的办法。（没说明为什么，也没有和这些工作对比）



### 数据集：

M4Scripted Meeting Corpus。每个都有一组按照固定顺序的预定义好的群体行为。4个参会者，6个可能出现的位置。

### 主要工作：

把会议记录分割为几秒为单位的小段，每个小段有自己的行为（讨论，记笔记，演示，独白，etc.）。识别出群体行为，并标记好首末时间。

- 总体是一个两阶段系统，分割+识别（RNN+HMM）

- 视频与音频是耦合好的（但是文中似乎更针对视频，对音频没有提及）
- 提取特征：多模态特征向量是从10s重复9s的视频中提取出来的（平均每秒一个特征）
- 提取特征时，会根据人头部的位置分割出一个区域，然后对单个人进行模式识别（姿态识别），结果是一个7维的特征流
- **单帧**的音频视频提取出的特征会被LSTM-RNN分类。选择LSTM-RNN是由于它优秀的处理滞后的能力，也就是处理长视频的能力，让它记住**更多**东西本文就记住了起码一秒的内容
- 分类结果作为后验喂给HMM，从而利用 Viterbi 算法提供分割

实验结果在一系列调优之后，准确率达到了92.66%

### 关键技术：

- LSTM（Long Short-Term Memory Recurrent Neural Net ）较长的短期记忆循环神经网络

  部分隐藏单元被记忆块（一个以上记忆元）替换掉了，记忆元的中心是有单循环连接的简单线性单元，初始权重为1.0 。

![image-20200105102747640](C:\Users\litia\AppData\Roaming\Typora\typora-user-images\image-20200105102747640.png)

​		可以看到，记忆单元可以接受不同的输入输出，核内是一个自循环。

​		LSTM-RNN有三层，输入有7节点，对应特征向量维度，隐层有4block，每个都有一个LSTMblock（LSTM是包	含在基本4块中的）输出层有8节点，对应类别，输出代表类别的概率。

- HMM框架

  LSTM-RNN直接暗示了每一帧的类别，但为了知道活动的开始和结束时间，本文使用HMM框架进行分割。但是并没有使用RNN的直接输出，而是添加了均值滤波（系数为5）（每个类都是有多种状态和高斯混合输出的连续系统？？？）具体HMM是怎么做到的，除了均值滤波我们一无所知。

### 遗留问题：

- RNN隐层数量会受到什么因素的影响吗？输入节点与输出节点是怎么定义的呢？
- 两层神经网络串接有什么好处（已知作用不同，这篇文章似乎是由于第二部分HMM是为了分割。此外呢？？）

### 可借鉴的点：

LSTM-RNN这个似乎比较节约内存的算法，也能考虑到前后帧的信息。而且考虑的比较多。

---

# End-to End Instance Segmentation with Recurrent Attention

基于循环注意力的端到端实例分割（端到端特指LSTM） 文章编号08099522

### 背景：

##### 任务的挑战之处：

- 在场景中区分单个物体是个有挑战性的任务。传统图像分割很少关注场景中有多少个实例物体，这需要区分出附近的和被遮挡的物体。

- 结构化输出时，维度太多（像素数*对象数）也是一个大挑战

- **（重叠物体的）吸收也是一个大问题**，有时候需要把没有连在一起的两部分合并起来，非最大抑制（NMS non-maximal suppression）可以解决但是很难微调，掌握不好，物体就会和前面的物体有太多重叠。

- 计数问题（数物体数量）又基础又有挑战，解决办法一般是先探测（detection）再回归，或者用一个计数错误矩阵来有区别的学习？？（ learning discriminatively）

##### 实例分割的前人工作：

- 基于探测器的办法

  自顶向下的探测，自底向上merge，使用DMP探测器。然后使用分层图像模型来处理图像分割和重叠物体的吸收。探测box的实现办法有，区域提案和区域描述子，还有bounding box。先预测box再分割图像

- 基于图像模型的办法

  使用图像模型（Graphical model）表示实例和像素之间的依赖关系。还有人先使用CNN在稠密的图像补丁（可视为巡视框）上进行局部预测，然后构建dense CRF来产生全局连续的标签。保持不同补丁间的一致性。

  能量函数依赖于实例之间的一致性和清晰的深度（depth ordering）顺序

- 全卷积办法

  使用稠密多尺度的CNN预测，需要后处理：自底向上的merge，或者聚类（clustering），还有模板匹配，实力融合等

- RNN方法

  基于最大加权二值匹配的排列不可知（x）loss，他们获取整张图片的办法是单独地对待每个CNN feature map。不能分清离得远（两个实例间的距离远）的实例。

### 主要工作：

本文提出了一个带有注意力机制的end-to-end RNN架构去模拟人对实例的计数过程，同时产生了详细的实例分割。模拟的办法就是，顺序的产生感兴趣区域，同时在主区域分割实例对象。

具体而言，RNN利用视觉注意力，来执行实例分割。

利用时间链（temporal chain）一次输出一个实例，这样就解决了输出维度问题。也体现在动态动态NMS，利用已经分割好的物体来帮助序列中被遮挡的物体

主要只有一步，RNN注意力模型，中有四个主要模块。额外记忆、BOX net盒子，分割网络，评分网络

![image-20200107143544928](C:\Users\litia\AppData\Roaming\Typora\typora-user-images\image-20200107143544928.png)

### 技术方案：

- 额外记忆（external memory）：

提供详细的物体边界信息，让网络学会下一个区域是什么。canvas有10个channels，第一个channel不断添加上一次新加入的像素，其他通道存储输入图片（这是否是如何解决输出维度的办法呢？？）

- 盒子网络（box network）

首先是external mem搞的输入（10c）送给CNN得到feature map。接下来需要得到盒子的位置。为了防止普通的池化丢失位置信息，我们使用了**软注意力（动态池化）**，为了防止只看一次不能给予足够多的的信息判断盒子的位置，我们让LSTM多看几眼。（记忆长度长一点，但是长度不是过去的几张图，而是多找几个不同的位置），每次都喂入一个L维的向量。传递LSTM隐层的状态，从中获取预测box的坐标。（缩放因子+正则化中心点+size）使用高丝插值法提取子区域。



- 分割工作：

首先从盒子网络的子区域出发，利用一个CNN然后使用带有跳接层的deconvnet(反卷积网络) 然后上采样，然后生成分割结果。



- 评分工作：

从box网络中的隐层获取信息，终止条件是得分低于0.5 且最大需序列长度是类别数+1.



- loss function：

包括三部分：IOU & boxIOU & 评分交叉熵

IOU计算输出实例和真值的最大二分图匹配，这个匹配还对真实实例的顺序敏感。损失函数如下图：

![image-20200107152527874](C:\Users\litia\AppData\Roaming\Typora\typora-user-images\image-20200107152527874.png)

softboxIOU：为了防止两个盒子不重叠的时候梯度消失，就把真实box和预测box的IOU计算出来

单调分数loss:就是鼓励sorce是单调递减的，这样既可以尽早输出可能性高的那个

### 关键词：

DMP detector----搜索不到

- 动态NMS （non-maximal suppression）

  非最大抑制，考虑不同区域的重叠问题。根据score矩阵和region的坐标，找到score最大的bounding box，接下来计算每个box与当前bounding box的IOU，**去除iou大于阈值的**。剩下的box继续重复这个过程直到为空。

- graphical models概率图模型

  节点集中每个节点表示一个（或一组）随机变量，两节点的边表示变量间的概率关系。有两类：贝叶斯网络，也叫有向图模型以及马尔科夫随机场（无向图模型）

- energy function？？能量函数

  将输入变量和输出变量统一考虑，以最小化能量函数为目标进行优化，和loss有本质上的相似。

- FCN全卷积神经网络

  CNN排在前面的卷积层采用较小的感知域感知纹理特征，在后面的卷积层学习物体大小，位置，方向等抽象特征。FCN用于图像分割，就是只用卷积层，不用全连接层，结构一根直肠通大脑。如下图。最后的输出一般是低分辨率的，会通过上采样提高分辨率。但对细节不敏感，没有考虑像素间的关联。

  ![image-20200107162154651](C:\Users\litia\AppData\Roaming\Typora\typora-user-images\image-20200107162154651.png)

- 软注意力：

  一般都在寻找下一个关注位置的时候用到，对应的是hard-attention，hard-attention是用权重向量α决定产生下一个窗口的产生位置，soft-attention中，α只能决定位置在所有αi中的重要性。

